communication:
  http:
    endpoints:
      device_inference_result: /api/device_inference_result
      device_input: /api/device_input
      offloading_layer: /api/offloading_layer
      registration: /api/registration
    host: 0.0.0.0
    model: fomo_96x96
    ntp_server: 0.it.pool.ntp.org
    port: 8000
  mode:
  - http
  mqtt:
    broker_port: 1883
    broker_url: hostname.local
    client_id: edge
    model: fomo_96x96
    ntp_server: 0.it.pool.ntp.org
    topics:
      device_inference_result: device_01/model_inference_result
      device_input: device_01/input_data
      offloading_layer: device_01/offloading_layer
      registration: devices/
  websocket:
    endpoint: /ws
    host: 0.0.0.0
    model: fomo_96x96
    ntp_server: 0.it.pool.ntp.org
    port: 8080
delay_simulation:
  computation:
    enabled: false
    max: 0.002
    mean: 0.001
    min: 0.0005
    std_dev: 0.0002
    type: none
    value: 0.001
  network:
    enabled: false
    max: 0.015
    mean: 0.01
    min: 0.005
    std_dev: 0.002
    type: none
    value: 0.01
local_inference_mode:
  enabled: true
  probability: 0.01
model:
  fomo_96x96:
    input_height: 96
    input_width: 96
    last_offloading_layer: 58
